---
title: "Project Report"
author: "Ruolan Zeng(rxz171630), Vineet Vilas Amonkar(vva180000)"
date: "November 29, 2018"
output:
  html_document: default
  pdf_document: default
---
## Abstract:

In this project we are creating linear models using multiple linear regression on the price dataset and token dataset of the storj token from the Ethereum blockchain. 
Our response variable(y) is simple price return given by $\frac{P_t - P_{t-1}}{P_{t-1}}$ where, $p_t$ is the token price in dollar for $t^{th}$ day.  

The regressor variables(x1...xn) are as follows:  

1. No of token transactions per day
2. No of total token bought or sold per day
3. No of unique buyers per day
4. Percentage of investors who bought more than token per day.

## About the datasets:

We have been given two datasets:

1. Price data:  
This is the price dataset for storj token it contains 379 rows and 7 columns as follows:  

 a) Date  
 b) Open : Opening price of the token on that day  
 c) High : Max price of the token on that day  
 d) Low : Min price of the token on that day  
 e) Close : Closing price of the token on that day  
 f) Volume : Volume of the token on that day  
 g) Market Cap: Market Cap of that token on that day  

2. Token data:  

This is the storj token transation dataset which has 406131 rows and 4 columns as follows:  

 a) from_node : These are the id which sell the token in the transaction  
 b) to_node : These are the id which buy the token in the transaction  
 c) unixtime : unix time of the transaction  
 d) totalamount : total subunits of the storj token involved in the transaction  


## Initialization:

We start with loading the token data and price data:

```{r}
tokenData <- read.delim("networkstorjTX.txt", header = FALSE, sep = " ")
tokenFrame<- as.data.frame(tokenData)
colnames(tokenFrame)<-c('fromNode','toNode','unixTime','totalAmount')
priceData <- read.delim("storj", header = TRUE, sep = "\t")
```

## Preprocessing the token data:

Removing the Outliers:

We then remove the outliers from the token data. Here we will be removing all the totalamount values from the token dataset who has value greater than the total supply of the storj token. We are removing these values because no transaction can have totalamount greater than the total supply of the tokens.

```{r}
TotalSupply <- 424999998
Decimals <- 10^8
OutlierValue <- TotalSupply*Decimals
WithoutOutlierdata <- tokenFrame[ which(tokenFrame$totalAmount < OutlierValue),]
nrow(WithoutOutlierdata)
```

We can now see that the number of records of the token dataset have now reduced to 406078

Converting the Unix time to date format:

We will convert the unix time of the token data to the date format. This would help us in merging both the datasets.

```{r}
newwithoutoutlierdata <- WithoutOutlierdata
newwithoutoutlierdata$unixTime <- as.Date(as.POSIXct(WithoutOutlierdata$unixTime,origin="1970-01-01",tz="GMT"))
```

Converting the class of price data date from factor to Date:

```{r}
priceData$Date <- as.Date(priceData$Date, "%m/%d/%Y")
```

## The response variable:

We will now calculate the response variable from the price data using the open column. The first few records of the response variable are as follows: 

```{r echo=FALSE}
return <- numeric(nrow(priceData))
return[379] <- priceData$Open[379]
for (i in 378:1) {
  return[i] <- (priceData$Open[i]-priceData$Open[i+1])/priceData$Open[i+1]
}
priceData$return <- return
head(priceData$return)
```

# Merging the datasets:

We will then merge both the datasets according to date which would help us in calculating the regressor variables.

```{r}
colnames(newwithoutoutlierdata)<-c('fromNode','toNode','Date','totalAmount')
newdataset <- merge(newwithoutoutlierdata,priceData,by = "Date")
```

We can see that the records have now decreased to 404257 this was because of the date difference between the price data and token data.

```{r echo = FALSE,eval = FALSE}
#token data dates
summary(newwithoutoutlierdata$Date)
#price data dates
summary(priceData$Date)
#dates after merging
summary(newdataset$Date)
```

## Feature Engineering:

We will now be calculating the first feature for creating the linear model:

1. Number of transactions that happened each day

The first few records are

```{r echo=FALSE}
frequencytrans <- table(newdataset$Date)
freqtrans<- as.data.frame(frequencytrans)
colnames(freqtrans) <- c("Date","no_of_trans")
freqtrans$Date <- as.Date(freqtrans$Date)
head(freqtrans$no_of_trans)
```

Now lets create a table which contains the regressor and response variable:

```{r echo = FALSE}
newsimpletable <- merge(priceData,freqtrans,by = "Date")
newsimpletable<- newsimpletable[,c(-6:-7)]
```

## Simple Linear Regression 1: 

Data preparation:

This involves univariate and bivariate analysis:

**Univariate Analysis**:

In this we will check for outliers and then remove them by capping our data to the max value.To remove majority of the outlier we are capping the data 92% quantile. Then we will alsocheck the response variable. 

```{r echo =FALSE}


par(mfrow = c(1,3))
bx = boxplot(newsimpletable$no_of_trans,ylim = c(0,5000),main = "with outlier",ylab ="no of trans" )

newsimpletable$no_of_trans<-ifelse(newsimpletable$no_of_trans>2275,2274.36,newsimpletable$no_of_trans)
boxplot(newsimpletable$no_of_trans, main ="without outlier",ylab = "no of trans")
#quantile(newsimpletable$no_of_trans, seq(0,1,0.02))
#bx$stats
boxplot(newsimpletable$return, main = "with outliers",ylab ="simple return")

```

But for simple return response varaible case we won't be removing any outliers as we don't want to have any impact on the response variable.


**Bivariate Analysis**:

In this analysis we will draw the scatterplot between the regressor and the response variable

but before we do that it is important to shift our response variable up by one row because we will be using yesterday to model today's response.

```{r }

shift <- function(x, n){
  c(x[-(seq(n))], rep(NA, n))
}


newsimpletable$return <- shift(newsimpletable$return, 1)
newsimpletable <- newsimpletable[1:(nrow(newsimpletable)-1),]
head(newsimpletable$return)
#plot(newsimpletable$no_of_trans,newsimpletable$return)
```

We can see that there isn't much relation between no of transactions each day and the simple return variable. We can confirm this by finding the correlation between the two

```{r}
cor(newsimpletable[,c(6,7)])
```

After completing the analysis we move ahead to fit the linear model.

```{r}
final_data <- lm(return~no_of_trans,data=newsimpletable)
summary(final_data)
```

From the summary of the linear model we can clearly see that it is not a good model, the p-values of the intercept and the regressor are very high, also the r-square conveys only 2% of the response variable.

**Testing**  

We can test this linear model using the plot function:

```{r echo=FALSE ,warning=FALSE, error=FALSE, message=FALSE}
library(lmtest)
par(mfrow = c(2,2))
plot(final_data)
```

lets try to interpret these 4 plots one by one:

1. **Residuals vs fitted**:

Even though we see a horizontal line in this plot we can see that the residuals are not evenly spread across the line.It may not suggest a pattern but we can see most of the points in the left speculating a non-linear behaviour

2. **Normal Q-Q**:

The plot leads us to believe that the residuals follow normality as most of the points are seen to lie on the line or near it although few observations such as 42,2 and 156 are significantly away from the line.

3. **Scale-Location**:

The horizontal line in this plot suggests that homoscedasticity is observed in the residuals.

4. **Residuals vs leverage**:

This plots finds the observations which have a high influence on the regression model according to the cooks distance. We can see that observation 42 is out of the region thus is an outlier which could have an impact on the model if we do remove or decide to keep it in the model.

## Multiple Linear Regression:

We will now create three new features for our multiple regression model: 

1. Total number of tokens involved per day:

We will first divide the total amount of each transaction with number of sub units of the storj token(10^8) to get the number of tokens, then we will group by and sum each amount according to the date  

First few records are as follows

```{r echo = FALSE}
newdataset$totalAmount <- (newdataset$totalAmount/(10^8))
tokentable <- aggregate(newdataset$totalAmount, by = list(Category = newdataset$Date), FUN = sum)

colnames(tokentable)<- c("Date","total_token")
newsimpletable <- merge(newsimpletable,tokentable,by = "Date")
head(newsimpletable$total_token)
```

2. Number of Unique buyers per day: 

In this we group the dataset according to the date and then count the number of unique buyers for each day.  

First few records are as follows

```{r echo = FALSE}

buyerstable <- aggregate(data=newdataset, toNode ~ Date, function(x) length(unique(x)))

colnames(buyerstable) <- c("Date","unique_buyers")
newsimpletable  <- merge(newsimpletable,buyerstable,by = "Date")
head(newsimpletable$unique_buyers)
```

3. Percentage of investors who have bought more than 10 tokens:

In this we will first need to find the total number of investors per day and then find the  total tokens  bought by each investor per day. then we have to find the number of investors who bought more than 10 token that day.  

First few records are as follows  

```{r echo =FALSE ,message=FALSE ,error=FALSE}
library(dplyr)
investortable <- newdataset %>% group_by(Date)
totalinvestor_table<- summarize(investortable , total_investors = n_distinct(toNode))
newinvestortable <- newdataset %>% group_by(Date,toNode)
newinvestortable_totaltoken <- summarise(newinvestortable,total_token = sum(totalAmount))
subsetnewinvestortable_totaltoken <- newinvestortable_totaltoken[ which(newinvestortable_totaltoken$total_token>10), ]
finalinvestortable <- summarise(subsetnewinvestortable_totaltoken, final_investors = n_distinct(toNode))
newfinalinvestortable <- merge(totalinvestor_table,finalinvestortable,by = "Date")
newfinalinvestortable$percentage_investors <- (newfinalinvestortable$final_investors/newfinalinvestortable$total_investors)*100
newsimpletable <- merge(newsimpletable,newfinalinvestortable,by = "Date")
head(newsimpletable$percentage_investors)
```

Now that we have all the required features lets do the analysis as we did for the simple linear regression:

**Univariate analysis**:

Create a boxplot of unique buys regressor variable and then we check for the number of tokens(and capping at 94%) and percentage of investors variable:

```{r echo = FALSE}
par(mfrow=c(2,3))
bx = boxplot(newsimpletable$unique_buyers, main ="with outlier",ylab ="no of buyers")
#quantile(newsimpletable$unique_buyers, seq(0,1,0.02))
newsimpletable$unique_buyers<-ifelse(newsimpletable$unique_buyers>3087,3088,newsimpletable$unique_buyers)
boxplot(newsimpletable$unique_buyers,main ="without outliers",ylab = "no of buyers")


bx = boxplot(newsimpletable$total_token, main="with outlier", ylab ="no of tokens")
#quantile(newsimpletable$total_token, seq(0,1,0.02))
newsimpletable$total_token<-ifelse(newsimpletable$total_token>5791001,5791001,newsimpletable$total_token)
boxplot(newsimpletable$total_token, main="without outliers", ylab="no of tokens")



bx = boxplot(newsimpletable$percentage_investors, main="with outliers", ylab ="% of investors")
#quantile(newsimpletable$percentage_investors, seq(0,1,0.02))
newsimpletable$percentage_investors<-ifelse(newsimpletable$percentage_investors<60,61.2,newsimpletable$percentage_investors)
boxplot(newsimpletable$percentage_investors,main="without outliers", ylab="% of investors")
```


 After the univariate analysis lets do the **bivariate analysis**:
 
 plot number of transactions vs return:  
 plot total token vs return:  
 plot unique buyers vs return:  
 plot percentage investors vs return:  
 
 
 
```{r echo=FALSE}
par(mfrow=c(2,2))
plot(newsimpletable$total_token,newsimpletable$return,xlab ="no of tokens",ylab ="simple return")
plot(newsimpletable$no_of_trans,newsimpletable$return,xlab ="no of trans",ylab ="simple return")
plot(newsimpletable$unique_buyers,newsimpletable$return,xlab ="no of buyers",ylab ="simple return")
plot(newsimpletable$percentage_investors,newsimpletable$return,xlab ="percentage of buyers",ylab ="simple return")
```
 
After analysing lets create an initial multiple regression linear model :

We use the car library to calculate variable inflation factor and find the multicollinearity

```{r error=FALSE ,message=FALSE}
final_data3 <- lm(return~no_of_trans+total_token+unique_buyers+percentage_investors,data = newsimpletable)
library(car)
vif(final_data3)



```


Since the VIF for all the regressor variables is not much higher than 5 we will keep all of them in the initial model

```{r}
summary(final_data3)
```

From the summary we can see that the p-value for the variables is very high suggesting that there is no linear relation between the regressor variable and the response variables.



But before giving up on this we haven't yet used any features from the price data lets use the inherent features such as open, low, high etc to create a new linear model and see how we fare:

We first find the multicollinearity and then use the step function to find the right combination of features:  

```{r echo=FALSE ,error =FALSE,message=FALSE,eval=TRUE}

final_data6 <- lm(return~no_of_trans+total_token+unique_buyers+percentage_investors+Open+High+Low,data = newsimpletable)
library(car)
vif(final_data6)
```

Finally, we check the summary and plot of our final data model:


```{r echo=FALSE}
#anothernewsimpletable <- merge(priceData,freqtrans,by = "Date")
#summary(anothernewsimpletable)
#anothernewsimpletable<- anothernewsimpletable[,c(-6,-7)]
#shift <- function(x, n){
 # c(x[-(seq(n))], rep(NA, n))
#}


#anothernewsimpletable$return <- shift(anothernewsimpletable$return, 1)
#anothernewsimpletable <- anothernewsimpletable[1:(nrow(anothernewsimpletable)-1),]
#plot(anothernewsimpletable$no_of_trans,anothernewsimpletable$return)
#anothernewsimpletable <- merge(anothernewsimpletable,tokentable,by = "Date")
#anothernewsimpletable  <- merge(anothernewsimpletable,buyerstable,by = "Date")
#anothernewsimpletable <- merge(anothernewsimpletable,newfinalinvestortable,by = "Date")
#summary(anothernewsimpletable)
#cor(anothernewsimpletable[,c(2:12)])

#summary(final_data6)
final_data10 <- lm(return~total_token+Open+High+Low,data = newsimpletable)
#summary(final_data10)

#final_data8 <- lm(return~no_of_trans+total_token+unique_buyers+percentage_investors+High+Low,data = newsimpletable)
#summary(final_data8)
#vif(final_data8)
#final_data9 <- lm(return~no_of_trans+total_token+unique_buyers+percentage_investors+High,data = newsimpletable)
#vif(final_data9)
#summary(final_data9)
#final_data10 <- lm(return~total_token+Open+High+Low,data = newsimpletable)
summary(final_data10)

par(mfrow=c(2,2))
plot(final_data10)
```


Conclusion:

As we can see when we use the price data columns and remove the features which have high p-value we get R^2^ value of 71%. 

We have analysed how we can use simple and multiple linear regression to create linear models by doing feature extraction on the storj token and price data.
The model can be redeveloped and tested with different features to improve the R-squared value however the method of creation and analysis is mostly similar.

Thank You
